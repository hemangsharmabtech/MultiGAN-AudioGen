{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyfLUleSHQYi"
      },
      "source": [
        "#Generator Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86x7qFcDHQYj",
        "outputId": "3c15b1ec-e0af-4d9d-e743-ba1a2dc061bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Model loaded with input_dim=30456 and frozen!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Latents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… Latents saved at C:\\Users\\cl502_11\\MG\\Feature Extraction\\GANs Inputs\\Generator\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import joblib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 8192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8192, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 8192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8192, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        reconstructed = self.decoder(latent)\n",
        "        return latent, reconstructed\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, mel_dir, mfcc_dir):\n",
        "        self.mel_files = sorted([os.path.join(mel_dir, f) for f in os.listdir(mel_dir) if f.endswith(\".npy\")])\n",
        "        self.mfcc_files = sorted([os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")])\n",
        "        if not self.mel_files or not self.mfcc_files:\n",
        "            raise ValueError(\"No .npy files found!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.mel_files), len(self.mfcc_files))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel = torch.tensor(np.load(self.mel_files[idx]), dtype=torch.float32)\n",
        "        mfcc = torch.tensor(np.load(self.mfcc_files[idx]), dtype=torch.float32)\n",
        "        return mel, mfcc, os.path.basename(self.mel_files[idx])\n",
        "\n",
        "# âœ… Paths\n",
        "AUTOENCODER_MODEL_PATH = r\"C:\\Users\\cl502_11\\MG\\Models\\VQ-VAE + GANs\\all hp tuned.joblib\"\n",
        "INPUT_MEL_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\Latents for 2nd Model\\INPUT\\mel_spectrograms\"\n",
        "INPUT_MFCC_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\Latents for 2nd Model\\INPUT\\mfccs\"\n",
        "MY_LATENT_SAVE_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\GANs Inputs\\Generator\"\n",
        "os.makedirs(MY_LATENT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# âœ… Fix your trained input dimension paaji!\n",
        "trained_input_dim = 30456  # ðŸš€ This MUST match your model training input size\n",
        "\n",
        "model = AutoEncoder(trained_input_dim).to(device)\n",
        "state_dict = joblib.load(AUTOENCODER_MODEL_PATH)\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "print(f\"âœ… Model loaded with input_dim={trained_input_dim} and frozen!\\n\")\n",
        "\n",
        "def extract_latents(dataset, save_dir):\n",
        "    for mel, mfcc, filename in tqdm(dataset, desc=\"Extracting Latents\"):\n",
        "        mel = mel.to(device)\n",
        "        mfcc = mfcc.to(device)\n",
        "\n",
        "        # ðŸ”¥ Concatenate along feature axis\n",
        "        combined = torch.cat((mel, mfcc), dim=0)  # Shape (mel_channels + mfcc_channels, time_steps)\n",
        "\n",
        "        # ðŸ”¥ Now pad this combined to match the width (time_steps) that gives 30456 after flatten\n",
        "        # Example: If combined is (141, 216), total = 141 * 216 = 30456 âœ…\n",
        "        expected_channels = 141\n",
        "        expected_timesteps = 216\n",
        "        current_channels, current_timesteps = combined.shape\n",
        "\n",
        "        # Pad channels or time-steps if necessary (just to be safe)\n",
        "        if current_channels != expected_channels or current_timesteps != expected_timesteps:\n",
        "            padded = F.pad(combined, (0, expected_timesteps - current_timesteps, 0, expected_channels - current_channels))\n",
        "        else:\n",
        "            padded = combined\n",
        "\n",
        "        # ðŸ”¥ Flatten correctly\n",
        "        combined_flat = padded.flatten().unsqueeze(0).to(device)  # Shape [1, 30456]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            latent, _ = model(combined_flat)\n",
        "\n",
        "        latent_np = latent.squeeze(0).cpu().numpy()\n",
        "        latent_filename = filename.replace('.npy', '_latent.npy')\n",
        "        np.save(os.path.join(save_dir, latent_filename), latent_np)\n",
        "\n",
        "    print(f\"\\nâœ… Latents saved at {save_dir}\")\n",
        "\n",
        "# âœ… Extraction Call\n",
        "my_dataset = CustomDataset(INPUT_MEL_DIR, INPUT_MFCC_DIR)\n",
        "extract_latents(my_dataset, MY_LATENT_SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gw-OEzxyHQYl"
      },
      "source": [
        "#Discriminator Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FH3OUaDEHQYl"
      },
      "outputs": [],
      "source": [
        "VQVAE_MODEL_PATH = r\"C:\\Users\\cl502_11\\MG\\Models\\VQ-VAE + GANs\\all hp tuned.joblib\"  # Replace with your trained VQ-VAE model\n",
        "KK_MEL_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\DataChunk1 (29 Files)\\80_10_10\\mel_spectrograms\\train\"\n",
        "KK_MFCC_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\DataChunk1 (29 Files)\\80_10_10\\mfccs\\train\"\n",
        "REAL_LATENT_SAVE_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\GANs Inputs\\Discriminator\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WaQv70THHQYl",
        "outputId": "da64863a-97c3-4030-af82-c8323c3899d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Full VQ-VAE Model Loaded and Frozen!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting KK Real Latents: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 767/767 [00:10<00:00, 70.77it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "âœ… KK Real Latents saved at C:\\Users\\cl502_11\\MG\\Feature Extraction\\GANs Inputs\\Discriminator\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import joblib\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "# âœ… Full VQ-VAE Model Definition (Matches saved model)\n",
        "class VQVAE(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(VQVAE, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(input_dim, 8192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8192, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 1024)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(1024, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4096, 8192),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(8192, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.encoder(x)\n",
        "        reconstructed = self.decoder(latent)\n",
        "        return latent, reconstructed\n",
        "\n",
        "# âœ… Dataset for KK's Mel + MFCC\n",
        "class KKDataset(Dataset):\n",
        "    def __init__(self, mel_dir, mfcc_dir):\n",
        "        self.mel_files = sorted([os.path.join(mel_dir, f) for f in os.listdir(mel_dir) if f.endswith(\".npy\")])\n",
        "        self.mfcc_files = sorted([os.path.join(mfcc_dir, f) for f in os.listdir(mfcc_dir) if f.endswith(\".npy\")])\n",
        "        if not self.mel_files or not self.mfcc_files:\n",
        "            raise ValueError(\"No .npy files found!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.mel_files), len(self.mfcc_files))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel = torch.tensor(np.load(self.mel_files[idx]), dtype=torch.float32)\n",
        "        mfcc = torch.tensor(np.load(self.mfcc_files[idx]), dtype=torch.float32)\n",
        "        return mel, mfcc, os.path.basename(self.mel_files[idx])\n",
        "\n",
        "# âœ… Paths\n",
        "VQVAE_MODEL_PATH = r\"C:\\Users\\cl502_11\\MG\\Models\\VQ-VAE + GANs\\all hp tuned.joblib\"  # Replace with your trained VQ-VAE model\n",
        "KK_MEL_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\DataChunk1 (29 Files)\\80_10_10\\mel_spectrograms\\train\"\n",
        "KK_MFCC_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\DataChunk1 (29 Files)\\80_10_10\\mfccs\\train\"\n",
        "REAL_LATENT_SAVE_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\GANs Inputs\\Discriminator\"\n",
        "os.makedirs(REAL_LATENT_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "trained_input_dim = 30456  # Match your training\n",
        "\n",
        "# âœ… Load the Full VQ-VAE Model\n",
        "vqvae = VQVAE(trained_input_dim).to(device)\n",
        "vqvae_state = joblib.load(VQVAE_MODEL_PATH)\n",
        "vqvae.load_state_dict(vqvae_state)\n",
        "vqvae.eval()\n",
        "print(f\"âœ… Full VQ-VAE Model Loaded and Frozen!\\n\")\n",
        "\n",
        "for param in vqvae.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# âœ… Latent Extraction Function\n",
        "def extract_kk_latents(dataset, save_dir):\n",
        "    for mel, mfcc, filename in tqdm(dataset, desc=\"Extracting KK Real Latents\"):\n",
        "        mel = mel.to(device)\n",
        "        mfcc = mfcc.to(device)\n",
        "\n",
        "        combined = torch.cat((mel, mfcc), dim=0)\n",
        "        expected_channels = 141\n",
        "        expected_timesteps = 216\n",
        "        cur_channels, cur_timesteps = combined.shape\n",
        "\n",
        "        if cur_channels != expected_channels or cur_timesteps != expected_timesteps:\n",
        "            padded = F.pad(combined, (0, expected_timesteps - cur_timesteps,\n",
        "                                      0, expected_channels - cur_channels))\n",
        "        else:\n",
        "            padded = combined\n",
        "\n",
        "        combined_flat = padded.flatten().unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            latent, _ = vqvae(combined_flat)  # âœ… Extract through full model to access encoder\n",
        "\n",
        "        latent_np = latent.squeeze(0).cpu().numpy()\n",
        "        latent_filename = filename.replace('.npy', '_kk_latent.npy')\n",
        "        np.save(os.path.join(save_dir, latent_filename), latent_np)\n",
        "\n",
        "    print(f\"\\nâœ… KK Real Latents saved at {save_dir}\")\n",
        "\n",
        "# âœ… Run Extraction\n",
        "kk_dataset = KKDataset(KK_MEL_DIR, KK_MFCC_DIR)\n",
        "extract_kk_latents(kk_dataset, REAL_LATENT_SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyxUuy0THQYm"
      },
      "source": [
        "#FINAL GANs model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcH4KwIPHQYm"
      },
      "outputs": [],
      "source": [
        "# âœ… Best hyperparameters from Optuna (Paste these manually)\n",
        "best_params = {\n",
        "    'hidden_dim': 1476,\n",
        "    'dropout': 0.49094941961091343,\n",
        "    'lr_gen': 0.00024773548667528797,\n",
        "    'lr_disc': 3.314136329501845e-05,\n",
        "    'batch_size': 32\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OYkKVrkHQYn",
        "outputId": "715e61ff-0547-4ca4-de1f-b76ad4eb9303"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 27.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 1 Completed - Generator Loss: 10249.6728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.06it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 2 Completed - Generator Loss: 4991.5491\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 36.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 3 Completed - Generator Loss: 4139.3735\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 4 Completed - Generator Loss: 4289.4713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 5 Completed - Generator Loss: 3542.1500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 6 Completed - Generator Loss: 3930.7398\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 7 Completed - Generator Loss: 3328.1774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 8 Completed - Generator Loss: 4055.0819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 9 Completed - Generator Loss: 4135.8629\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 10 Completed - Generator Loss: 3609.9335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 11 Completed - Generator Loss: 3533.1101\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 12 Completed - Generator Loss: 4056.2602\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 13 Completed - Generator Loss: 3794.4526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 14 Completed - Generator Loss: 3172.9015\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 15 Completed - Generator Loss: 4501.7958\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 16 Completed - Generator Loss: 3629.0079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 17 Completed - Generator Loss: 3280.5852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 18 Completed - Generator Loss: 3091.6324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 36.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 19 Completed - Generator Loss: 3553.6685\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 36.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 20 Completed - Generator Loss: 3209.1853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 37.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 21 Completed - Generator Loss: 3066.8652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 37.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 22 Completed - Generator Loss: 3200.2808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 23 Completed - Generator Loss: 3176.9828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 24 Completed - Generator Loss: 3249.6139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 25 Completed - Generator Loss: 2904.8331\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 26 Completed - Generator Loss: 3340.8473\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 27 Completed - Generator Loss: 2702.1733\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 41.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 28 Completed - Generator Loss: 3652.2020\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 29 Completed - Generator Loss: 2594.0032\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 40.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 30 Completed - Generator Loss: 3375.9651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 31 Completed - Generator Loss: 3323.2930\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.01it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 32 Completed - Generator Loss: 3390.8353\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 33 Completed - Generator Loss: 3540.6109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 34 Completed - Generator Loss: 3255.7062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.49it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 35 Completed - Generator Loss: 2808.3835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 36 Completed - Generator Loss: 2912.3825\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 37 Completed - Generator Loss: 4014.9534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 38 Completed - Generator Loss: 3104.6624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 39 Completed - Generator Loss: 3108.4297\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 40 Completed - Generator Loss: 2952.8754\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 41 Completed - Generator Loss: 2936.0211\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 37.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 42 Completed - Generator Loss: 3104.8664\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 43 Completed - Generator Loss: 3387.6511\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 37.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 44 Completed - Generator Loss: 3328.3770\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 37.04it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 45 Completed - Generator Loss: 3626.9293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 37.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 46 Completed - Generator Loss: 2765.1084\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 36.11it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 47 Completed - Generator Loss: 3125.2751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 38.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 48 Completed - Generator Loss: 3419.8038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 49/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 49 Completed - Generator Loss: 3017.8166\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 50/50: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [00:00<00:00, 39.34it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Epoch 50 Completed - Generator Loss: 2923.3707\n",
            "\n",
            "âœ… Models Saved Successfully at C:\\Users\\cl502_11\\MG\\Models\\GANs\\Final_Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import joblib\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "GEN_INPUT_PATH = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\GANs Inputs\\Generator\\MW_latent.npy\"\n",
        "DISC_REAL_DIR = r\"C:\\Users\\cl502_11\\MG\\Feature Extraction\\GANs Inputs\\Discriminator\"\n",
        "SAVE_DIR = r\"C:\\Users\\cl502_11\\MG\\Models\\GANs\\Final_Training\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "latent_dim = 1024\n",
        "EPOCHS = 50  # ðŸ”¥ Set your desired epochs\n",
        "\n",
        "# âœ… Dataset for Discriminator Real Samples\n",
        "class RealLatentDataset(Dataset):\n",
        "    def __init__(self, directory):\n",
        "        self.files = sorted([os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.npy')])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(np.load(self.files[idx]), dtype=torch.float32)\n",
        "\n",
        "# âœ… Generator and Discriminator Classes\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, dropout):\n",
        "        super(Generator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, latent_dim)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, dropout):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(latent_dim, hidden_dim),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# âœ… Load Best Hyperparameters\n",
        "hidden_dim = best_params['hidden_dim']\n",
        "dropout = best_params['dropout']\n",
        "lr_gen = best_params['lr_gen']\n",
        "lr_disc = best_params['lr_disc']\n",
        "batch_size = best_params['batch_size']\n",
        "\n",
        "# âœ… Model Initialization\n",
        "G = Generator(latent_dim, hidden_dim, dropout).to(device)\n",
        "D = Discriminator(latent_dim, hidden_dim, dropout).to(device)\n",
        "\n",
        "optimizer_G = optim.Adam(G.parameters(), lr=lr_gen)\n",
        "optimizer_D = optim.Adam(D.parameters(), lr=lr_disc)\n",
        "criterion_adv = nn.BCELoss()\n",
        "criterion_recon = nn.L1Loss()\n",
        "\n",
        "# âœ… Load Generator Input (Your Latent)\n",
        "gen_input = torch.tensor(np.load(GEN_INPUT_PATH), dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "# âœ… Load Discriminator Real Data\n",
        "real_dataset = RealLatentDataset(DISC_REAL_DIR)\n",
        "real_loader = DataLoader(real_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# âœ… Training Loop\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    G.train()\n",
        "    D.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for real_data in tqdm(real_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
        "        real_data = real_data.to(device)\n",
        "\n",
        "        # ðŸ”¥ Train Discriminator\n",
        "        optimizer_D.zero_grad()\n",
        "        real_preds = D(real_data)\n",
        "        fake_data = G(gen_input).detach().repeat(real_data.size(0), 1)\n",
        "        fake_preds = D(fake_data)\n",
        "\n",
        "        d_real_loss = criterion_adv(real_preds, torch.ones_like(real_preds))\n",
        "        d_fake_loss = criterion_adv(fake_preds, torch.zeros_like(fake_preds))\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # ðŸ”¥ Train Generator\n",
        "        optimizer_G.zero_grad()\n",
        "        gen_output = G(gen_input)\n",
        "        adv_loss = criterion_adv(D(gen_output), torch.ones((1, 1), device=device))\n",
        "        recon_loss = criterion_recon(gen_output, real_data[0].unsqueeze(0))  # Optional recon loss\n",
        "        g_loss = adv_loss + 0.5 * recon_loss\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "        epoch_loss += g_loss.item()\n",
        "\n",
        "    print(f\"âœ… Epoch {epoch} Completed - Generator Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# âœ… Save Final Models\n",
        "joblib.dump(G.state_dict(), os.path.join(SAVE_DIR, \"Generator_final.joblib\"))\n",
        "joblib.dump(D.state_dict(), os.path.join(SAVE_DIR, \"Discriminator_final.joblib\"))\n",
        "print(\"\\nâœ… Models Saved Successfully at\", SAVE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBiLxbrEHQYn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "MelodyGAN",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}